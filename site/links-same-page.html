<!doctype html>
<html>
<head>
	<meta charset="utf-8">
	<title>Links</title>
</head>
<body>
	<h1 id="top">Links to Sections of The Same Page</h1>
	<section>
		<ul>
			<!-- Link to every section in the page -->
			<li><a href="#section1">#section1</a></li>
			<li><a href="#section2">#section2</a></li>
			<li><a href="#section3">#section3</a></li>
			<li><a href="#section4">#section4</a></li>
			<li><a href="#section5">#section5</a></li>
			<li><a href="#section6">#section6</a></li> 
		</ul>

	</section>

	<section id="section1">
		<h3>(#section1) Section 1</h3>
		<p>In communications and information processing, code is a system of rules to convert information—such as a letter, word, sound, image, or gesture—into another form or representation, sometimes shortened or secret, for communication through a communication channel or storage in a storage medium. An early example is the invention of language, which enabled a person, through speech, to communicate what they saw, heard, felt, or thought to others. But speech limits the range of communication to the distance a voice can carry, and limits the audience to those present when the speech is uttered. The invention of writing, which converted spoken language into visual symbols, extended the range of communication across space and time.</p>
	</section>

		<section id="section2">
		<h3>(#section2) Section 2</h3>
		<p>The process of encoding converts information from a source into symbols for communication or storage. Decoding is the reverse process, converting code symbols back into a form that the recipient understands, such as English or/and Spanish. One reason for coding is to enable communication in places where ordinary plain language, spoken or written, is difficult or impossible. For example, semaphore, where the configuration of flags held by a signaler or the arms of a semaphore tower encodes parts of the message, typically individual letters and numbers. Another person standing a great distance away can interpret the flags and reproduce the words sent.</p>
	</section>
		<section id="section3">
		<h3>(#section3) Section 3</h3>
		<p>In information theory and computer science, a code is usually considered as an algorithm that uniquely represents symbols from some source alphabet, by encoded strings, which may be in some other target alphabet. An extension of the code for representing sequences of symbols over the source alphabet is obtained by concatenating the encoded strings. Before giving a mathematically precise definition, this is a brief example.</p>
	</section>
		<section id="section4">
		<h2>(#section4) Section 4</h2>
		<p>The mapping is a code, whose source alphabet is the set \. Using the extension of the code, the encoded string 0011001011 can be grouped into codewords as 0 011 0 01 011, and these in turn can be decoded to the sequence of source symbols acabc. Using terms from formal language theory, the precise mathematical definition of this concept is as follows: let S and T be two finite sets, called the source and target alphabets, respectively. A code C:\, S \to T^  is a total function mapping each symbol from S to a sequence of symbols over T, and the extension of C to a homomorphism of S^  into T^, which naturally maps each sequence of source symbols to a sequence of target symbols, is referred to as its extension.</p>
	</section>
		<section id="section5">
		<h2>(#section5) Section 5</h2>
		<p>In this section, we consider codes that encode each source  character by a code word from some dictionary, and concatenation of such code words give us an encoded string. Variable-length codes are especially useful when clear text characters have different probabilities; see also entropy encoding. A prefix code is a code with the "prefix property": there is no valid code word in the system that is a prefix  of any other valid code word in the set. Huffman coding is the most known algorithm for deriving prefix codes. Prefix codes are widely referred to as "Huffman codes" even when the code was not produced by a Huffman algorithm. Other examples of prefix codes are country calling codes, the country and publisher parts of ISBNs, and the Secondary Synchronization Codes used in the UMTS WCDMA 3G Wireless Standard. Kraft's inequality characterizes the sets of codeword lengths that are possible in a prefix code. Virtually any uniquely decodable one-to-many code, not necessary a prefix one, must satisfy Kraft's inequality.</p>
	</section>
	<div>
		<h2><a name="section6">(#section6) Section 6</a></h2>
		<p>
			Back to top: <a href="#top">Back to Top</a>
		</p>
	</div>
</body>
</html>